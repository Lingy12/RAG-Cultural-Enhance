[1mdiff --git a/eval_src/dataset.py b/eval_src/dataset.py[m
[1mindex 6422f52..b06c3a5 100755[m
[1m--- a/eval_src/dataset.py[m
[1m+++ b/eval_src/dataset.py[m
[36m@@ -25,54 +25,15 @@[m [mimport logging[m
 [m
 from datasets import load_dataset[m
 [m
[31m-from dataset_src.cross_xquad import cross_xquad_dataset[m
[31m-from dataset_src.cross_mmlu import cross_mmlu_dataset[m
[31m-from dataset_src.cross_logiqa import cross_logiqa_dataset[m
 from dataset_src.sg_eval import sg_eval_dataset[m
[31m-from dataset_src.cn_eval import cn_eval_dataset[m
 from dataset_src.us_eval import us_eval_dataset[m
 from dataset_src.ph_eval import ph_eval_dataset[m
[31m-from dataset_src.open_sg_qa import open_sg_qa_dataset[m
[31m-from dataset_src.sing2eng import sing2eng_dataset[m
[31m-from dataset_src.flores_ind2eng import flores_ind2eng_dataset[m
[31m-from dataset_src.flores_vie2eng import flores_vie2eng_dataset[m
[31m-from dataset_src.flores_zho2eng import flores_zho2eng_dataset[m
[31m-from dataset_src.flores_zsm2eng import flores_zsm2eng_dataset[m
[31m-from dataset_src.mmlu import mmlu_dataset[m
[31m-from dataset_src.mmlu_full import mmlu_full_dataset[m
[31m-from dataset_src.c_eval import c_eval_dataset[m
[31m-from dataset_src.c_eval_full import c_eval_full_dataset[m
[31m-from dataset_src.cmmlu import cmmlu_dataset[m
[31m-from dataset_src.cmmlu_full import cmmlu_full_dataset[m
[31m-from dataset_src.zbench import zbench_dataset[m
[31m-from dataset_src.ind_emotion import ind_emotion_dataset[m
[31m-from dataset_src.ocnli import ocnli_dataset[m
[31m-from dataset_src.c3 import c3_dataset[m
[31m-from dataset_src.dream import dream_dataset[m
[31m-from dataset_src.samsum import samsum_dataset[m
[31m-from dataset_src.dialogsum import dialogsum_dataset[m
[31m-from dataset_src.sst2 import sst2_dataset[m
[31m-from dataset_src.cola import cola_dataset[m
[31m-from dataset_src.qqp import qqp_dataset[m
[31m-from dataset_src.mnli import mnli_dataset[m
[31m-from dataset_src.qnli import qnli_dataset[m
[31m-from dataset_src.wnli import wnli_dataset[m
[31m-from dataset_src.rte import rte_dataset[m
[31m-from dataset_src.mrpc import mrpc_dataset[m
[31m-[m
[31m-[m
[31m-[m
[31m-[m
[32m+[m[32mfrom logger_config import get_logger[m
 [m
 [m
 [m
 # =  =  =  =  =  =  =  =  =  =  =  Logging Setup  =  =  =  =  =  =  =  =  =  =  =  =  = [m
[31m-logger = logging.getLogger(__name__)[m
[31m-logging.basicConfig([m
[31m-    format  = "%(asctime)s - %(levelname)s - %(name)s - %(message)s",[m
[31m-    datefmt = "%m/%d/%Y %H:%M:%S",[m
[31m-    level   = logging.INFO,[m
[31m-)[m
[32m+[m[32mlogger = get_logger(__name__)[m
 # =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = [m
 [m
 [m
[36m@@ -112,27 +73,10 @@[m [mclass Dataset(object):[m
      [m
 [m
     def data_format(self):[m
[31m-[m
[31m-        if self.dataset_name == 'cross_xquad':[m
[31m-            self.dataset_processor = cross_xquad_dataset(self.raw_data, self.prompt_index, self.support_langs, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'cross_mmlu':[m
[31m-            self.dataset_processor = cross_mmlu_dataset(self.raw_data, self.prompt_index, self.support_langs, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'cross_logiqa':[m
[31m-            self.dataset_processor = cross_logiqa_dataset(self.raw_data, self.prompt_index, self.support_langs, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'sg_eval':[m
[32m+[m[32m        if self.dataset_name == 'sg_eval':[m
             self.dataset_processor = sg_eval_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
             self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
 [m
[31m-        elif self.dataset_name == 'cn_eval':[m
[31m-            self.dataset_processor = cn_eval_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-        [m
         elif self.dataset_name == 'us_eval':[m
             self.dataset_processor = us_eval_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
             self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[36m@@ -141,114 +85,6 @@[m [mclass Dataset(object):[m
             self.dataset_processor = ph_eval_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
             self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
 [m
[31m-        elif self.dataset_name == 'open_sg_qa':[m
[31m-            self.dataset_processor = open_sg_qa_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'sing2eng':[m
[31m-            self.dataset_processor = sing2eng_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'flores_ind2eng':[m
[31m-            self.dataset_processor = flores_ind2eng_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-        [m
[31m-        elif self.dataset_name == 'flores_vie2eng':[m
[31m-            self.dataset_processor = flores_vie2eng_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-        [m
[31m-        elif self.dataset_name == 'flores_zho2eng':[m
[31m-            self.dataset_processor = flores_zho2eng_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'flores_zsm2eng':[m
[31m-            self.dataset_processor = flores_zsm2eng_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'mmlu':[m
[31m-            self.dataset_processor = mmlu_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'mmlu_full':[m
[31m-            self.dataset_processor = mmlu_full_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'c_eval':[m
[31m-            self.dataset_processor = c_eval_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'c_eval_full':[m
[31m-            self.dataset_processor = c_eval_full_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'cmmlu':[m
[31m-            self.dataset_processor = cmmlu_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'cmmlu_full':[m
[31m-            self.dataset_processor = cmmlu_full_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-        [m
[31m-        elif self.dataset_name == 'zbench':[m
[31m-            self.dataset_processor = zbench_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'ind_emotion':[m
[31m-            self.dataset_processor = ind_emotion_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'ocnli':[m
[31m-            self.dataset_processor = ocnli_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'c3':[m
[31m-            self.dataset_processor = c3_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'dream':[m
[31m-            self.dataset_processor = dream_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'samsum':[m
[31m-            self.dataset_processor = samsum_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-        [m
[31m-        elif self.dataset_name == 'dialogsum':[m
[31m-            self.dataset_processor = dialogsum_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'sst2':[m
[31m-            self.dataset_processor = sst2_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'cola':[m
[31m-            self.dataset_processor = cola_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'qqp':[m
[31m-            self.dataset_processor = qqp_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'mnli':[m
[31m-            self.dataset_processor = mnli_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'qnli':[m
[31m-            self.dataset_processor = qnli_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'wnli':[m
[31m-            self.dataset_processor = wnli_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'rte':[m
[31m-            self.dataset_processor = rte_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
[31m-        elif self.dataset_name == 'mrpc':[m
[31m-            self.dataset_processor = mrpc_dataset(self.raw_data, self.prompt_index, self.eval_mode)[m
[31m-            self.raw_data, self.data_plain = self.dataset_processor.prepare_model_input()[m
[31m-[m
         else:[m
             raise NotImplementedError("Dataset {} not implemented yet".format(self.dataset_name))[m
 [m
[1mdiff --git a/eval_src/evaluate.py b/eval_src/evaluate.py[m
[1mindex 8025c5e..2fce8ae 100755[m
[1m--- a/eval_src/evaluate.py[m
[1m+++ b/eval_src/evaluate.py[m
[36m@@ -24,13 +24,16 @@[m [mfrom tqdm import trange[m
 from dataset import Dataset[m
 from model   import Model[m
 from rag import RAG[m
[32m+[m[32mfrom logger_config import get_logger[m
[32m+[m
[32m+[m[32mlogger = get_logger(__name__)[m
 # =  =  =  =  =  =  =  =  =  =  =  Logging Setup  =  =  =  =  =  =  =  =  =  =  =  =  = [m
[31m-logger = logging.getLogger(__name__)[m
[31m-logging.basicConfig([m
[31m-    format  = "%(asctime)s - %(levelname)s - %(name)s - %(message)s",[m
[31m-    datefmt = "%m/%d/%Y %H:%M:%S",[m
[31m-    level   = logging.INFO,[m
[31m-)[m
[32m+[m[32m# logger = logging.getLogger(__name__)[m
[32m+[m[32m# logging.basicConfig([m
[32m+[m[32m    # format  = "%(asctime)s - %(levelname)s - %(name)s - %(message)s",[m
[32m+[m[32m    # datefmt = "%m/%d/%Y %H:%M:%S",[m
[32m+[m[32m    # level   = logging.INFO,[m
[32m+[m[32m# )[m
 # =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = [m
 [m
 # assume batch size is 1[m
[36m@@ -87,6 +90,7 @@[m [mdef do_model_prediction(dataset, model):[m
     for i in trange(0, len(dataset.data_plain), leave=False):[m
         inputs  = dataset.data_plain[i][m
         outputs = model.generate(inputs)[m
[32m+[m[32m        print(outputs)[m
         model_predictions.extend(outputs)[m
     return model_predictions[m
 [m
[1mdiff --git a/eval_src/model.py b/eval_src/model.py[m
[1mindex b5d0467..fab7a0b 100755[m
[1m--- a/eval_src/model.py[m
[1m+++ b/eval_src/model.py[m
[36m@@ -19,16 +19,16 @@[m [mimport sys[m
 sys.path.append('.')[m
 [m
 import logging[m
[31m-[m
[32m+[m[32mfrom logger_config import get_logger[m
 [m
 [m
 # =  =  =  =  =  =  =  =  =  =  =  Logging Setup  =  =  =  =  =  =  =  =  =  =  =  =  = [m
[31m-logger = logging.getLogger(__name__)[m
[31m-logging.basicConfig([m
[31m-    format  = "%(asctime)s - %(levelname)s - %(name)s - %(message)s",[m
[31m-    datefmt = "%m/%d/%Y %H:%M:%S",[m
[31m-    level   = logging.INFO,[m
[31m-)[m
[32m+[m[32mlogger = get_logger(__name__)[m
[32m+[m[32m# logging.basicConfig([m
[32m+[m[32m    # format  = "%(asctime)s - %(levelname)s - %(name)s - %(message)s",[m
[32m+[m[32m    # datefmt = "%m/%d/%Y %H:%M:%S",[m
[32m+[m[32m    # level   = logging.INFO,[m
[32m+[m[32m# )[m
 # =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = [m
 [m
 [m
[1mdiff --git a/scripts/combined_json_single.py b/scripts/combined_json_single.py[m
[1mindex 52033a5..cf11e6e 100644[m
[1m--- a/scripts/combined_json_single.py[m
[1m+++ b/scripts/combined_json_single.py[m
[36m@@ -11,19 +11,33 @@[m [mfrom typing import Iterable, List[m
 [m
 logger = get_logger(__name__)[m
 [m
[32m+[m[32mtarget_words = ['singapore', 'united state','u.s.', 'philippines'][m
 def save_docs_to_jsonl(array:Iterable[Document], file_path:str)->None:[m
     with open(file_path, 'w') as jsonl_file:[m
         for doc in tqdm(array):[m
             jsonl_file.write(doc.json() + '\n')[m
 [m
[31m-def contains_any(s, words):[m
[31m-    return any(word in s for word in words)[m
[32m+[m[32mdef check_filter(s, words, exclude):[m
[32m+[m[32m    exclude_words = set(target_words) - set(words)[m
[32m+[m[41m    [m
[32m+[m[32m    for word in target_words:[m
[32m+[m[32m        in_s = word in s[m
[32m+[m[32m        if word in exclude_words and exclude and in_s: # should remove if exclude words in doc and exclude is triggered.[m
[32m+[m[32m            return False[m
[32m+[m[32m        if word in words and not in_s: # should remove if the target word not in doc[m
[32m+[m[32m            return False[m
[32m+[m[32m        if word in words and in_s: # checking next word[m
[32m+[m[32m            continue[m
[32m+[m
[32m+[m[32m    return True[m
[32m+[m
 [m
 def to_doc(text):[m
     return Document(page_content=text)[m
 [m
[31m-def combine_json(data_dir, name, filter_words: List[str]):[m
[31m-    [m
[32m+[m[32mdef combine_json(data_dir, name, filter_words: List[str], exclude=False):[m
[32m+[m[32m    logger.info(filter_words)[m
[32m+[m[32m    logger.info(exclude)[m
     if not os.path.exists('./processed_data'):[m
         os.makedirs('./processed_data', exist_ok=True)[m
 [m
[36m@@ -45,7 +59,7 @@[m [mdef combine_json(data_dir, name, filter_words: List[str]):[m
         for line in lines:[m
             data = json.loads(line)[m
             [m
[31m-            if not contains_any(data['text'].lower(), filter_words):[m
[32m+[m[32m            if not check_filter(data['text'].lower(), filter_words, exclude):[m
                 continue[m
             [m
 [m
[1mdiff --git a/scripts/evaluate_rag_tfidf.py b/scripts/evaluate_rag_tfidf.py[m
[1mindex 45fdc1d..f09d40d 100644[m
[1m--- a/scripts/evaluate_rag_tfidf.py[m
[1m+++ b/scripts/evaluate_rag_tfidf.py[m
[36m@@ -7,30 +7,42 @@[m [mimport sys[m
 import os[m
 from pathlib import Path[m
 import transformers[m
[31m-transformers.set_seed(43)[m
[31m-[m
[32m+[m[32mfrom transformers import set_seed[m
[32m+[m[32m# transformers.set_seed(43)[m
[32m+[m[32mimport torch[m
[32m+[m[32mdef make_deterministic(seed):[m
[32m+[m[32m    set_seed(seed)[m
[32m+[m[32m    # torch.use_deterministic_algorithms(True)[m
[32m+[m[32m    torch.backends.cudnn.benchmark = False[m
[32m+[m[32m    torch.backends.cudnn.deterministic = True[m
 def to_doc(text):[m
     return Document(page_content=text)[m
 [m
[32m+[m[32mmake_deterministic(0)[m
 model_path = '/home/shared_LLMs/gemma-2b-it/'[m
[31m-prompt = './prompt/prompt_test.txt'[m
[31m-vector_store = os.path.normpath(sys.argv[1])[m
[31m-retrival_threshold = float(sys.argv[2])[m
[32m+[m[32mprompt = './prompt/prompt_eval.txt'[m
[32m+[m[32m# vector_store = os.path.normpath(sys.argv[1])[m
[32m+[m[32mretrival_threshold = float(sys.argv[1])[m
 [m
 # Build the TF-IDF vector store[m
[31m-start_time = time.time()[m
[31m-print('Loading vector store...')[m
[31m-vs = TfidfStore(top_k=5,saved_vs=vector_store)[m
[31m-print('Vector store loaded.')[m
[31m-end_time = time.time()[m
[31m-[m
[32m+[m[32m# start_time = time.time()[m
[32m+[m[32m# print('Loading vector store...')[m
[32m+[m[32m# vs = TfidfStore(top_k=5,saved_vs=vector_store)[m
[32m+[m[32m# print('Vector store loaded.')[m
[32m+[m[32m# end_time = time.time()[m
 [m
[31m-rag_model = RAG(model_path=model_path, vector_store=vs, prompt_template=prompt, device='cuda', verbose=1, retrieval_threshold=retrival_threshold)[m
 [m
[31m-datasets = ['sg_eval', 'us_eval', 'ph_eval'][m
[32m+[m[32mdatasets = {'sg_eval': './vector_store/wiki_sg_exclusive_2_2_None_1_0.01_True.pkl'}[m
[32m+[m[32m            # 'us_eval': './vector_store/wiki_us_ex_filtered_1_1_None_1_1.0_True.pkl',[m[41m [m
[32m+[m[32m            # 'ph_eval': './vector_store/wiki_ph_exclusive_1_1_None_1_1.0_True.pkl'}[m
 # eval_lang = ['English'][m
 num_prompt = 1[m
 [m
 for dataset in datasets:[m
     for i in range(1, num_prompt + 1):[m
[31m-        eval_rag(rag=rag_model, dataset_name=dataset, prompt_index=i, eval_lang=['English'], eval_mode='zero_shot', model_name=str(Path(os.path.basename(vector_store)).with_suffix('')) + '_' + str(retrival_threshold))[m
[32m+[m[32m        print('Loading vector store...')[m
[32m+[m[32m        vs = TfidfStore(top_k=5,saved_vs=datasets[dataset])[m
[32m+[m[32m        print('Vector store loaded.')[m
[32m+[m
[32m+[m[32m        rag_model = RAG(model_path=model_path, vector_store=vs, prompt_template=prompt, retrieval_threshold=retrival_threshold, verbose=1)[m
[32m+[m[32m        eval_rag(rag=rag_model, dataset_name=dataset, prompt_index=i, eval_lang=['English'], eval_mode='zero_shot', model_name=str(Path(os.path.basename(datasets[dataset])).with_suffix('')) + '_' + str(retrival_threshold))[m
[1mdiff --git a/scripts/model_trail.py b/scripts/model_trail.py[m
[1mindex 5211fa0..fc8ae28 100644[m
[1m--- a/scripts/model_trail.py[m
[1m+++ b/scripts/model_trail.py[m
[36m@@ -12,7 +12,8 @@[m [mdef to_doc(text):[m
 model_path = '/home/shared_LLMs/gemma-2b-it'[m
 prompt = sys.argv[1][m
 vector_store = sys.argv[2][m
[31m-top_k = sys.argv[3][m
[32m+[m[32mtop_k = int(sys.argv[3])[m
[32m+[m[32mthreshold = float(sys.argv[4])[m
 [m
 # Build the TF-IDF vector store[m
 start_time = time.time()[m
[36m@@ -25,9 +26,9 @@[m [mend_time = time.time()[m
 [m
 print(f"Loading time is : {end_time - start_time} seconds")[m
 [m
[31m-rag_model = RAG(model_path=model_path, vector_store=vs, prompt_template=prompt, device='cuda', verbose=0, retrieval_threshold=0.1)[m
[32m+[m[32mrag_model = RAG(model_path=model_path, vector_store=vs, prompt_template=prompt, device='cuda', verbose=0, retrieval_threshold=threshold)[m
 [m
 while True:[m
     query = input('Enter the query:')[m
     answer = rag_model.generate(query, show_ori=False, max_new_tokens=64)[m
[31m-    print('Model Response: ' + answer[0])[m
[32m+[m[32m    # print('Model Response: ' + answer[0])[m
[1mdiff --git a/src/rag.py b/src/rag.py[m
[1mindex 7c40f79..efd574d 100644[m
[1m--- a/src/rag.py[m
[1m+++ b/src/rag.py[m
[36m@@ -60,7 +60,8 @@[m [mclass RAG:[m
         [m
         outputs = outputs[:,input_ids.input_ids.shape[-1]:] # mask input[m
         outputs = self.tokenizer.batch_decode(outputs)[m
[31m-        [m
[32m+[m[32m        if len(retrival_string) > 0:[m
[32m+[m[32m            outputs[0] += '[RAG]'[m
         logger.info('model answer: ' + outputs[0])[m
         return outputs[m
 [m
